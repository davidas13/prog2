{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from lib.ReadFiles import read_csv\n",
    "from lib.FaceDetection import find_faces\n",
    "from lib.Prepocessing import image_equalizer\n",
    "from lib.plot import *\n",
    "def reshape_dataset(X, y):\n",
    "    images = [np.array(dx) for dx in X]\n",
    "    images = np.asarray(images, dtype=np.uint8)\n",
    "    labels = np.array(y).tolist()\n",
    "    return images, labels\n",
    "\t\n",
    "emotions = [\"Marah\", \"Jijik\", \"Takut\",\n",
    "            \"Senang\", \"Sedih\", \"Terkejut\", \"Biasa saja\"]  # inisialisasi index dan emosi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _x, _y, _u = read_csv(\"input/fer2013_small.csv\")\n",
    "# print(np.array(_x).shape)\n",
    "\n",
    "# x_new, y_new, u_new = [], [], []\n",
    "# for i, pixel in enumerate(_x):\n",
    "# \tfor norm, (x,y,w,h) in find_faces(np.array(pixel, dtype=np.uint8).reshape(48, 48)):\n",
    "# \t\tif norm.size >0:\n",
    "# \t\t\tx_new.append(pixel)\n",
    "# \t\t\ty_new.append(_y[i])\n",
    "# \t\t\tu_new.append(_u[i])\n",
    "# print(np.array(x_new).shape)\n",
    "\n",
    "# x_, y_ = image_equalizer(x_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.DataFrame({\"emotion\": y_, \"pixels\": x_, \"usage\": u_new})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _x_test, _y_test = dataframe.loc[dataframe[\"usage\"].str.endswith(\"Test\") ,\"pixels\"], dataframe.loc[dataframe[\"usage\"].str.endswith(\"Test\"), \"emotion\"]\n",
    "# x_test, y_test = reshape_dataset(_x_test, _y_test)\n",
    "# plot_figure(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membaca model dari trainig fihserface\n",
    "import joblib\n",
    "fisher = joblib.load(\"model/fisherface_training.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_pred = []\n",
    "# f_extract = []\n",
    "# for i in range(len(x_test)):\n",
    "# \t_p = fisher.predict(x_test[i]) #prediksi fisherface\n",
    "# \t_q = fisher.extract(x_test[i]) #ekstrasi fitur fisherface\n",
    "# \tf_pred.append(_p)\n",
    "# \tf_extract.append(_q)\n",
    "\n",
    "# print(accuracy_score(y_test, f_pred))\n",
    "# cm_plot(y_test, f_pred, 'Test Fisherface', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from doctest import OutputChecker\n",
    "# import tensorflow as tf\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.layers import Activation, Dense, Input\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# def normalize_data(x,y):\n",
    "#     x = np.asarray(x, dtype=np.float32).reshape(len(x), -1)\n",
    "#     y =  to_categorical(y)\n",
    "#     return x,y\n",
    "\n",
    "# class ModelBackprop(object):\n",
    "# \tdef __init__(self, x=None, y=None, n_hidden=0, lr=0, path = None):\n",
    "# \t\tself.lr = lr\n",
    "# \t\tself.n_output = 7\n",
    "# \t\tself.n_epoch = 1000\n",
    "# \t\tself.n_hidden = n_hidden\n",
    "# \t\tself.model = Sequential()\n",
    "# \t\tself.sgd = SGD(learning_rate=lr)\n",
    "\t\t\n",
    "# \t\tself.init()\n",
    "\n",
    "# \t\tif x is not None and y is not None:\n",
    "# \t\t\tx, y = normalize_data(x, y)\n",
    "# \t\t\tself.compute(x, y)\n",
    "# \t\tif path is not None:\n",
    "# \t\t\tself.saved(path)\n",
    "\n",
    "# \tdef init(self):\n",
    "# \t\tself.model.add(Dense(self.n_hidden, input_shape=(6,)))\n",
    "# \t\tself.model.add(Activation(\"sigmoid\"))\n",
    "# \t\tself.model.add(Dense(self.n_output))\n",
    "# \t\tself.model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "# \tdef compute(self, x, y):\n",
    "# \t\tself.model.compile(loss=\"MSE\", optimizer=self.sgd, metrics=['accuracy'])\n",
    "# \t\tself.history = self.model.fit(x, y, epochs=self.n_epoch, batch_size=3, verbose=0)\n",
    "\t\n",
    "# \tdef predict(self,x):\n",
    "# \t\tx = np.asarray(x, dtype=np.float32).reshape(len(x), -1)\n",
    "# \t\treturn self.model.predict(x)\n",
    "\n",
    "# \tdef saved(self, path):\n",
    "# \t\tto_json = self.model.to_json()\n",
    "# \t\twith open(\"model.json\", 'w') as json_file:\n",
    "# \t\t\tjson_file.write(to_json)\n",
    "# \t\tself.model.save_weights(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bpn = ModelBackprop(x = f_extract, y = y_test, n_hidden=128, lr=0.25, path='model/weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_plot(bpn.history, 'Test History', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "#load model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model/weight.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Loaded\n",
      "Emotion: Senang\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "WIDTH = 48\n",
    "HEIGHT = 48\n",
    "x=None\n",
    "y=None\n",
    "\n",
    "full_size_image = cv2.imread(\"test.png\")\n",
    "print(\"Image Loaded\")\n",
    "gray=cv2.cvtColor(full_size_image,cv2.COLOR_RGB2GRAY)\n",
    "face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = face.detectMultiScale(gray, 1.1  , 6, minSize=(24,24))\n",
    "\n",
    "#detecting facesq\n",
    "for (x, y, w, h) in faces:\n",
    "\t\troi_gray = gray[y:y + h, x:x + w]\n",
    "\t\tcropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "\t\tcv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "\t\tcv2.rectangle(full_size_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        #predicting the emotion\n",
    "\t\txhat = fisher.extract(cropped_img)\n",
    "\t\tyhat= loaded_model.predict(xhat)\n",
    "\t\tcv2.putText(full_size_image, emotions[int(np.argmax(yhat))], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\t\tprint(\"Emotion: \"+emotions[int(np.argmax(yhat))])\n",
    "\n",
    "cv2.imshow('Emotion', full_size_image)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# while True:\n",
    "# \trval, vFrame = cap.read()\n",
    "# \tvFrame = cv2.flip(vFrame, 1)\n",
    "# \tfaceCascade = cv2.CascadeClassifier('C:\\Program Files\\Python37\\Lib\\site-packages\\cv2\\data\\haarcascade_frontalface_alt.xml')\n",
    "# \tcv2image = cv2.cvtColor(vFrame, cv2.COLOR_RGB2BGR)\n",
    "# \tcv2image = cv2.cvtColor(cv2image, cv2.COLOR_BGR2GRAY)\n",
    "# \tfaces = faceCascade.detectMultiScale(cv2image, scaleFactor=1.1, minNeighbors=6, minSize=(24,24))\n",
    "\n",
    "# \tfor (x,y, w, h) in faces:\n",
    "# \t\troi_gray = cv2image[y:y + h, x:x + w]\n",
    "# \t\tcropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "# \t\tcv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "# \t\tcv2.rectangle(vFrame, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "#         #predicting the emotion\n",
    "# \t\txhat = fisher.extract(cropped_img)\n",
    "# \t\tyhat= loaded_model.predict(xhat)\n",
    "# \t\tcv2.putText(vFrame, emotions[int(np.argmax(yhat))], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "# \tcv2.imshow('Emotion', vFrame)\n",
    "# \tif cv2.waitKey(30) & 0xff == ord('q'):\n",
    "# \t\tbreak\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
